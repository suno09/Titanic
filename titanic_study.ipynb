{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "import pickle\n",
    "from time import time, strftime, gmtime\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from math import factorial\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread, Lock\n",
    "\n",
    "nan = np.NaN\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file and show head\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "original_df = pd.concat([df_train, df_test], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                          Name     Sex  \\\n",
       "1304         1305       NaN       3            Spector, Mr. Woolf    male   \n",
       "1305         1306       NaN       1  Oliva y Ocana, Dona. Fermina  female   \n",
       "1306         1307       NaN       3  Saether, Mr. Simon Sivertsen    male   \n",
       "1307         1308       NaN       3           Ware, Mr. Frederick    male   \n",
       "1308         1309       NaN       3      Peter, Master. Michael J    male   \n",
       "\n",
       "       Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "1304   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "1305  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "1306  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "1307   NaN      0      0              359309    8.0500   NaN        S  \n",
       "1308   NaN      1      1                2668   22.3583   NaN        C  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>929</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name   Sex    Ticket        Cabin Embarked\n",
       "count               1309  1309      1309          295     1307\n",
       "unique              1307     2       929          186        3\n",
       "top     Kelly, Mr. James  male  CA. 2343  C23 C25 C27        S\n",
       "freq                   2   843        11            6      914"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', False, dtype('int64')),\n",
       " ('Survived', True, dtype('float64')),\n",
       " ('Pclass', False, dtype('int64')),\n",
       " ('Name', False, dtype('O')),\n",
       " ('Sex', False, dtype('O')),\n",
       " ('Age', True, dtype('float64')),\n",
       " ('SibSp', False, dtype('int64')),\n",
       " ('Parch', False, dtype('int64')),\n",
       " ('Ticket', False, dtype('O')),\n",
       " ('Fare', True, dtype('float64')),\n",
       " ('Cabin', True, dtype('O')),\n",
       " ('Embarked', True, dtype('O'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "list(zip(original_df.columns, original_df.isnull().any(), original_df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = original_df.Survived\n",
    "dataframe = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column NameType(Mr, Mrs, ...) from Name\n",
    "dataframe['NameType'] = [re.sub(r'.+?, (.+?)\\..*', r'\\1', name) for name in dataframe.Name]\n",
    "dataframe.NameType = dataframe.NameType.replace(\n",
    "    ['Sir', 'Capt', 'Major', 'Don', 'Rev', 'Jonkheer', 'Col'],\n",
    "    \"Mr\"\n",
    ")\n",
    "dataframe.NameType = dataframe.NameType.replace(\n",
    "    ['Mlle', 'Lady', 'Mme', 'Miss', 'Mrs', 'the Countess', 'Dona'],\n",
    "    \"Ms\"\n",
    ")\n",
    "\n",
    "# replace row contains sex = female and nameType = Dr by Ms\n",
    "dataframe.loc[(dataframe.Sex == \"female\") & (dataframe.NameType == \"Dr\"), 'NameType'] = \"Ms\"\n",
    "# replace row contains sex = male and nameType = Dr by Mr\n",
    "dataframe.loc[(dataframe.Sex == \"male\") & (dataframe.NameType == \"Dr\"), 'NameType'] = \"Mr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the nan value of age by the mean of group of Name type\n",
    "dataframe.Age = dataframe.groupby([\"NameType\"]).transform(lambda a: a.fillna(a.mean())).Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create family size\n",
    "dataframe['FamilySize'] = dataframe.SibSp + dataframe.Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TicketNum from Ticket\n",
    "# replace Ticket \"LINE\" by \"3\" (all ticket \"LINE\" is Pclass 3)\n",
    "dataframe['TicketNum'] = [\n",
    "    re.sub(r'.+?\\b(\\d+)$', r'\\1', re.sub(r'LINE', r'3', ticket)) for ticket in dataframe.Ticket\n",
    "]\n",
    "# create TicketNumLen : the nbr of digits in TicketNum\n",
    "dataframe['TicketNumLen'] = dataframe.TicketNum.apply(lambda tn: len(str(tn)))\n",
    "# create TicketNumDigitStart : the digit which the ticket num starts\n",
    "dataframe['TicketNumDigitStart'] = dataframe.TicketNum.apply(lambda tn: str(tn)[0])\n",
    "# change type TicketNum to numeric\n",
    "dataframe.TicketNum = dataframe.TicketNum.astype(float)\n",
    "dataframe.TicketNumDigitStart = dataframe.TicketNumDigitStart.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna Embarked by get the closet point of notnull from the nullpoint\n",
    "columns = ['Pclass', 'Fare', 'TicketNum']\n",
    "df_embarked_isnull = dataframe[dataframe.Fare.notnull() & dataframe.Embarked.isnull()]\n",
    "indexes_embarked_isnull = df_embarked_isnull.index.values\n",
    "df_embarked_notnull = dataframe[dataframe.Fare.notnull() & dataframe.Embarked.notnull()].reset_index(drop=True)\n",
    "eds = euclidean_distances(df_embarked_isnull[columns].values, df_embarked_notnull[columns].values)\n",
    "indexes_min_dist_embarked = [min(enumerate(ed), key=itemgetter(1))[0] for ed in eds]\n",
    "dataframe.loc[indexes_embarked_isnull, 'Embarked'] = [\n",
    "    df_embarked_notnull.at[index, 'Embarked'] for index in indexes_min_dist_embarked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the nan value of Fare by the mean of group of \n",
    "# Pclass, Embarked, TicketNumLen, TicketNumDigitStart, FamilySize\n",
    "dataframe.Fare = dataframe.groupby(\n",
    "    ['Pclass', 'Embarked', 'TicketNumLen', 'TicketNumDigitStart', 'FamilySize']\n",
    ")['Fare'].transform(lambda f: f.fillna(f.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fare per person\n",
    "dataframe['FarePerPerson'] = dataframe.Fare / (dataframe.FamilySize + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the count of Cabin\n",
    "dataframe['CabinCount'] = dataframe.Cabin.apply(lambda cs: [nan, len(str(cs).strip().split())][cs is not nan])\n",
    "# Create Column and take the first letter of the cabin which contains a number of cabin\n",
    "dataframe['CabinCode'] = dataframe.Cabin.apply(\n",
    "    lambda cs: [\n",
    "        nan,\n",
    "        sorted(str(cs).strip().split(), key=len, reverse=True)[0][0]\n",
    "    ][cs is not nan]\n",
    ")\n",
    "# create the number of Cabin (nbr after the letter) (if exist one or more of cabins so get the first else 0)\n",
    "dataframe['NbrOfCabin'] = dataframe.Cabin.apply(\n",
    "    lambda cs: [nan, list(filter(lambda c: len(c) > 1, str(cs).strip().split()))][cs is not nan]\n",
    ")\n",
    "dataframe.NbrOfCabin = [\n",
    "    np.mean([int(c[1:]) for c in cs]) if (cs is not nan) and (cs != []) else nan \n",
    "    for cs in dataframe.NbrOfCabin\n",
    "]\n",
    "# dataframe[dataframe.Cabin.notnull()][\n",
    "#     ['CabinCode', 'CabinCount', 'NbrOfCabin', 'Cabin', 'Pclass', 'FamilySize', 'FarePerPerson',\n",
    "#      'Embarked', 'TicketNum', 'TicketNumLen', 'TicketNumDigitStart']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression |████████████████████████████████                  | 65.99 % (00:00:44)\n",
      "The best classifier is Decision Tree\n",
      "The accuracy : 81.36 %\n",
      "The columns : ['Pclass', 'FamilySize', 'Fare', 'TicketNum', 'TicketNumLen']\n",
      "Number of tests = 1141 / 1729 tests\n"
     ]
    }
   ],
   "source": [
    "## fillna of CabinCode by create a classification model\n",
    "start_time = time()\n",
    "data = dataframe[dataframe.CabinCode.notnull()][[\n",
    "    'CabinCode', 'Pclass', 'FamilySize', 'FarePerPerson', 'Fare',\n",
    "    'Embarked', 'TicketNum', 'TicketNumLen', 'TicketNumDigitStart'\n",
    "]]\n",
    "data_x = data.drop(['CabinCode'], 1)\n",
    "y = data.CabinCode.values\n",
    "\n",
    "object_cols = data_x.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = {}\n",
    "for obj_col in object_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(data_x[obj_col])\n",
    "    data_x[[obj_col]] = data_x[[obj_col]].apply(label_encoder.transform)\n",
    "    label_encoders[obj_col] = label_encoder\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": [LogisticRegression, {'random_state': 0}],\n",
    "    \"KNN\": [KNeighborsClassifier,\n",
    "            {'n_neighbors': 5, 'metric': 'minkowski', 'p': 2}],\n",
    "    \"SVM rbf\": [SVC, {'kernel': 'rbf', 'random_state': 0}],\n",
    "#     \"SVM poly\": [SVC, {'kernel': 'poly', 'random_state': 0}],\n",
    "    \"SVM sigmoid\": [SVC, {'kernel': 'sigmoid', 'random_state': 0}],\n",
    "#     \"SVM precomputed\": [SVC, {'kernel': 'precomputed', 'random_state': 0}],\n",
    "#     \"SVM linear\": [SVC, {'kernel': 'linear', 'random_state': 0}],\n",
    "    \"Naive Bayes\": [GaussianNB, {}],\n",
    "    \"Decision Tree\": [DecisionTreeClassifier, {'criterion': \"entropy\",\n",
    "                                               'random_state': 0}],\n",
    "    \"Random Forest\": [RandomForestClassifier,\n",
    "                      {'n_estimators': 10,\n",
    "                       'criterion': 'entropy',\n",
    "                       'random_state': 0}]\n",
    "}\n",
    "len_algorithms = classifiers.__len__()\n",
    "# count of all columns in data\n",
    "len_cols = data_x.columns.__len__()\n",
    "max_nbr_f = data_x.columns.__len__()\n",
    "min_nbr_f = max_nbr_f // 5 + 1\n",
    "nbr_tests = sum([\n",
    "    factorial(len_cols) / factorial(i) / factorial(len_cols - i) for i in range(min_nbr_f, max_nbr_f + 1)\n",
    "]) * len_algorithms\n",
    "columns_train = [\n",
    "    [col for index, col in enumerate(data_x.columns) if index in indexes_cols]\n",
    "    for nbr_features in range(max_nbr_f, min_nbr_f - 1, -1)\n",
    "    for indexes_cols in itertools.combinations(range(len_cols), nbr_features)\n",
    "]\n",
    "current_train = 0\n",
    "# use K fold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "cl_cabin_code = {'accuracy': -1, 'features': data_x.columns}\n",
    "\n",
    "# generate classifiers\n",
    "for columns in columns_train:\n",
    "    if len(cl_cabin_code['features']) - len(columns) == 2:\n",
    "        break\n",
    "        \n",
    "    X = data_x[columns].values.astype(np.float64)\n",
    "\n",
    "    for name_classifier, [classifier, params] in classifiers.items():\n",
    "#             print(name_classifier)\n",
    "        # Start generate model\n",
    "        ml_classifier = classifier(**params)\n",
    "        scores = cross_val_score(ml_classifier, X, y, cv=kf)    \n",
    "        # save the result\n",
    "        max_accuracy = max(scores)\n",
    "        # print the progression\n",
    "        current_train += 1\n",
    "        progress_value = current_train * 100. / nbr_tests\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(\"Progression |%-50s| %.2f %% (%s)\" %\n",
    "                         (\"\\u2588\" * int(progress_value / 2.),\n",
    "                          progress_value,\n",
    "                          strftime(\"%H:%M:%S\", gmtime(time() - start_time))\n",
    "                          )\n",
    "                         )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if (max_accuracy > cl_cabin_code['accuracy']) or (\n",
    "            (max_accuracy == cl_cabin_code['accuracy']) and (len(columns) < len(cl_cabin_code['features']))\n",
    "        ):\n",
    "            cl_cabin_code = {\n",
    "                \"x_y\": [X, y],\n",
    "#                 \"dummy_var\": onehotencoder,\n",
    "#                 \"feature_scaling\": sc,\n",
    "                \"classifier\": ml_classifier,\n",
    "                \"features\": list(columns),\n",
    "                \"algorithm\": name_classifier,\n",
    "                \"accuracy\": max_accuracy\n",
    "            }\n",
    "    \n",
    "# sort and view results\n",
    "print(\"\\nThe best classifier is %s\" % cl_cabin_code['algorithm'])\n",
    "print(\"The accuracy : %.2f %%\" % (cl_cabin_code['accuracy'] * 100.))\n",
    "print(\"The columns : %s\" % cl_cabin_code['features'])\n",
    "# print(\"The duration of execution : %s\" %\n",
    "#       strftime(\"%H hours %M minutes %S seconds\", gmtime(end_time - start_time))\n",
    "#       )\n",
    "print(\"Number of tests = %d / %d tests\" % (current_train, nbr_tests))        \n",
    "# add the test data to best classifier\n",
    "X, y = cl_cabin_code['x_y']\n",
    "cl_cabin_code['classifier'].fit(X, y)\n",
    "\n",
    "# save label encoders\n",
    "cl_cabin_code['label_encoders'] = label_encoders\n",
    "\n",
    "# Save best classifier to pickle as dictionary\n",
    "with open('classifiers/cl_cabin_code.pik', 'wb') as wp:\n",
    "    pickle.dump(cl_cabin_code, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Predict with Decision Tree\n",
      "False\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.CabinCode.isnull().any())\n",
    "# fillna CabinCode of dataframe \n",
    "print(\"Predict with %s\" % cl_cabin_code['algorithm'])\n",
    "\n",
    "df = dataframe[dataframe.CabinCode.isnull()][cl_cabin_code['features']]\n",
    "object_cols = df.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = cl_cabin_code['label_encoders']\n",
    "for obj_col in object_cols:\n",
    "    df[[obj_col]] = df[[obj_col]].apply(label_encoders[obj_col].transform)\n",
    "\n",
    "X = df.values.astype(np.float64)\n",
    "# predict with classifier\n",
    "y = cl_cabin_code['classifier'].predict(X)\n",
    "\n",
    "# dataframe.CabinCode = dataframe.CabinCode.replace([nan] * len(y), y)\n",
    "indexes_cabin_code_isnull = dataframe[dataframe.CabinCode.isnull()].index\n",
    "dataframe.loc[indexes_cabin_code_isnull, 'CabinCode'] = y\n",
    "print(dataframe.CabinCode.isnull().any())\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the nbr of cabin to 1 for cabin has 1 cabin in data\n",
    "dataframe.loc[dataframe.CabinCount.notnull() & dataframe.NbrOfCabin.isnull(), 'NbrOfCabin'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression |████████████                                      | 25.90 % (00:00:32)\n",
      "The best regressor is Decision Tree\n",
      "The accuracy : 90.63 %\n",
      "The columns : ['CabinCode', 'Pclass', 'FamilySize', 'FarePerPerson', 'Embarked', 'TicketNum', 'TicketNumDigitStart']\n",
      "Number of tests = 390 / 1506 tests\n"
     ]
    }
   ],
   "source": [
    "## fillna of CabinCount and NbrOfCabin by create a multi output regression model\n",
    "start_time = time()\n",
    "data = dataframe[dataframe.CabinCount.notnull()][[\n",
    "    'CabinCode', 'CabinCount', 'NbrOfCabin', 'Pclass', 'FamilySize', 'FarePerPerson', 'Fare',\n",
    "    'Embarked', 'TicketNum', 'TicketNumLen', 'TicketNumDigitStart'\n",
    "]]\n",
    "data_x = data.drop(['CabinCount', 'NbrOfCabin'], 1)\n",
    "y = data[['CabinCount', 'NbrOfCabin']].values\n",
    "\n",
    "object_cols = data_x.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = {}\n",
    "for obj_col in object_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(data_x[obj_col])\n",
    "    data_x[[obj_col]] = data_x[[obj_col]].apply(label_encoder.transform)\n",
    "    label_encoders[obj_col] = label_encoder\n",
    "\n",
    "regressors = {\n",
    "#     \"Polynomial Resgression\": [PolynomialFeatures, {}],\n",
    "    \"SVR rbf\": [SVR, {'kernel': 'rbf'}],\n",
    "#     \"SVR poly\": [SVR, {'kernel': 'poly'}],\n",
    "#     \"SVR sigmoid\": [SVR, {'kernel': 'sigmoid'}],\n",
    "    \"Decision Tree\": [DecisionTreeRegressor, {'criterion': \"mse\",\n",
    "                                              'random_state': 0}],\n",
    "    \"Random Forest\": [RandomForestRegressor,\n",
    "                      {'n_estimators': 10,\n",
    "                       'criterion': 'mse',\n",
    "                       'random_state': 0}]\n",
    "}\n",
    "len_algorithms = regressors.__len__()\n",
    "# count of all columns in data\n",
    "len_cols = data_x.columns.__len__()\n",
    "max_nbr_f = data_x.columns.__len__()\n",
    "min_nbr_f = max_nbr_f // 5 + 1\n",
    "nbr_tests = sum([\n",
    "    factorial(len_cols) / factorial(i) / factorial(len_cols - i) for i in range(min_nbr_f, max_nbr_f + 1)\n",
    "]) * len_algorithms\n",
    "columns_train = [\n",
    "    [col for index, col in enumerate(data_x.columns) if index in indexes_cols]\n",
    "    for nbr_features in range(max_nbr_f, min_nbr_f - 1, -1)\n",
    "    for indexes_cols in itertools.combinations(range(len_cols), nbr_features)\n",
    "]\n",
    "current_train = 0\n",
    "\n",
    "# use K fold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "reg_cabin_count_nbr = {'accuracy': -1, 'features': data_x.columns}\n",
    "\n",
    "# generate classifiers\n",
    "for columns in columns_train:\n",
    "    if len(reg_cabin_count_nbr['features']) - len(columns) == 2:\n",
    "        break\n",
    "        \n",
    "    X = data_x[columns].values.astype(np.float64)\n",
    "\n",
    "    # Feature Scaling\n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_x.fit_transform(X)\n",
    "    y_sc = sc_y.fit_transform(y)\n",
    "\n",
    "    for name_regressor, [regressor, params] in regressors.items():\n",
    "        # Start generate multi output model\n",
    "        ml_regressor = MultiOutputRegressor(regressor(**params))\n",
    "        scores = cross_val_score(ml_regressor, X, y_sc, scoring='neg_mean_squared_error', cv=kf)  \n",
    "        # save the result\n",
    "        max_accuracy = max(scores)\n",
    "        # print the progression\n",
    "        current_train += 1\n",
    "        progress_value = current_train * 100. / nbr_tests\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(\"Progression |%-50s| %.2f %% (%s)\" %\n",
    "                         (\"\\u2588\" * int(progress_value / 2.),\n",
    "                          progress_value,\n",
    "                          strftime(\"%H:%M:%S\", gmtime(time() - start_time))\n",
    "                          )\n",
    "                         )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if (max_accuracy > reg_cabin_count_nbr['accuracy']) or (\n",
    "            (max_accuracy == reg_cabin_count_nbr['accuracy']) and (\n",
    "                len(columns) < len(reg_cabin_count_nbr['features']))\n",
    "        ):\n",
    "            reg_cabin_count_nbr = {\n",
    "                \"x_y\": [X, y_sc],\n",
    "#                 \"dummy_var\": onehotencoder,\n",
    "                \"feature_scaling_x\": sc_x,\n",
    "                \"feature_scaling_y\": sc_y,\n",
    "                \"regressor\": ml_regressor,\n",
    "                \"features\": list(columns),\n",
    "                \"algorithm\": name_regressor,\n",
    "                \"accuracy\": max_accuracy\n",
    "            }\n",
    "\n",
    "print(\"\\nThe best regressor is %s\" % reg_cabin_count_nbr['algorithm'])\n",
    "print(\"The accuracy : %.2f %%\" % (100 + reg_cabin_count_nbr['accuracy'] * 100.))\n",
    "print(\"The columns : %s\" % reg_cabin_count_nbr['features'])\n",
    "# print(\"The duration of execution : %s\" %\n",
    "#       strftime(\"%H hours %M minutes %S seconds\", gmtime(end_time - start_time))\n",
    "#       )\n",
    "print(\"Number of tests = %d / %d tests\" % (current_train, nbr_tests))        \n",
    "# add the test data to best classifier\n",
    "X, y = reg_cabin_count_nbr['x_y']\n",
    "reg_cabin_count_nbr['regressor'].fit(X, y)\n",
    "\n",
    "# save label encoders\n",
    "reg_cabin_count_nbr['label_encoders'] = label_encoders\n",
    "\n",
    "# Save best classifier to pickle as dictionary\n",
    "with open('classifiers/reg_cabin_count_nbr.pik', 'wb') as wp:\n",
    "    pickle.dump(reg_cabin_count_nbr, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Predict with Decision Tree\n",
      "False\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.CabinCount.isnull().any())\n",
    "# fillna CabinCode of dataframe \n",
    "print(\"Predict with %s\" % reg_cabin_count_nbr['algorithm'])\n",
    "\n",
    "df = dataframe[dataframe.CabinCount.isnull()][reg_cabin_count_nbr['features']]\n",
    "object_cols = df.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = reg_cabin_count_nbr['label_encoders']\n",
    "for obj_col in object_cols:\n",
    "    df[[obj_col]] = df[[obj_col]].apply(label_encoders[obj_col].transform)\n",
    "\n",
    "X = df.values.astype(np.float64)\n",
    "# # use dummy variables for columns of types object\n",
    "# if reg_cabin_count_nbr['dummy_var']:\n",
    "#     X = reg_cabin_count_nbr['dummy_var'].transform(X).toarray()\n",
    "\n",
    "# Feature Scaling\n",
    "X = reg_cabin_count_nbr['feature_scaling_x'].transform(X)\n",
    "\n",
    "# predict with regressor and reverse feature scaling\n",
    "y = reg_cabin_count_nbr['feature_scaling_y'].inverse_transform(reg_cabin_count_nbr['regressor'].predict(X))\n",
    "\n",
    "indexes_cabin_count_isnull = dataframe[dataframe.CabinCount.isnull()].index\n",
    "dataframe.loc[indexes_cabin_count_isnull, ['CabinCount', 'NbrOfCabin']] = y\n",
    "print(dataframe.CabinCount.isnull().any())\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Sex to 'M' and 'F'\n",
    "dataframe.Sex = dataframe.Sex.transform(lambda s: s[0])\n",
    "# compute size of male and female in familySize + 1 by groupby of Ticket\n",
    "df_sum_sex = dataframe.groupby(['TicketNum', 'TicketNumLen', 'TicketNumDigitStart']).Sex.transform('sum')\n",
    "dataframe['MaleCount'] = df_sum_sex.transform(lambda s: s.count('m'))\n",
    "dataframe['FemaleCount'] = df_sum_sex.transform(lambda s: s.count('f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make diff that 1st class is better than 2nd class and 3rd class\n",
    "dataframe['PclassPower'] = 3. / dataframe.Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PclassPower and Fare\n",
    "dataframe['PclassPowerFare'] = dataframe.PclassPower * dataframe.Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person per Cabin \n",
    "dataframe['PersonPerCabin'] = (dataframe.FamilySize + 1) / dataframe.CabinCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare of cabin\n",
    "dataframe['FarePerCabin'] = dataframe.Fare / dataframe.CabinCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "with open('classifiers/dataframe_titanic.pik', 'wb') as wp:\n",
    "    pickle.dump(dataframe, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate pickle file which saves information for starting training \n",
    "df = dataframe.drop(['Survived'], 1)\n",
    "len_cols = len(df.columns)\n",
    "max_nbr_f = len_cols\n",
    "min_nbr_f = max_nbr_f // 5 + 1\n",
    "len_algorithms = 6\n",
    "nbr_tests = sum([\n",
    "    factorial(len_cols) / factorial(i) / factorial(len_cols - i) for i in range(min_nbr_f, max_nbr_f + 1)\n",
    "]) * len_algorithms\n",
    "columns_train = [\n",
    "    [col for index, col in enumerate(df.columns) if index in indexes_cols]\n",
    "    for nbr_features in range(max_nbr_f, min_nbr_f - 1, -1)\n",
    "    for indexes_cols in itertools.combinations(range(len_cols), nbr_features)\n",
    "]\n",
    "infos = {\n",
    "    'nbr_of_trains': nbr_tests,\n",
    "    'columns_train': columns_train,\n",
    "    'nbr_cols_done': 35443\n",
    "}\n",
    "# save the infos\n",
    "with open('classifiers/infos.pik', 'wb') as wp:\n",
    "    pickle.dump(infos, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After load the packages, start from here (ignore data preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classifiers/dataframe_titanic.pik', 'rb') as rp:\n",
    "    dataframe = pickle.load(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = dataframe\n",
    "# get the cols of type \"object\"\n",
    "object_cols = df_prep.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = {}\n",
    "for obj_col in object_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df_prep[obj_col])\n",
    "    df_prep[[obj_col]] = df_prep[[obj_col]].apply(label_encoder.transform)\n",
    "    label_encoders[obj_col] = label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99999931e-01, 6.43825599e-08, 2.14996993e-09, 1.17170709e-09,\n",
       "       4.01908731e-10, 2.78368187e-10, 1.07089918e-10, 5.87058521e-12,\n",
       "       4.16331480e-12, 2.50661982e-12, 2.21458436e-12, 1.43217804e-12,\n",
       "       1.11400652e-12, 9.37836783e-13, 6.86510923e-13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_prep.drop(['Survived'], 1)[:891].values.astype(np.float64)\n",
    "X_test = df_prep.drop(['Survived'], 1)[891:].values.astype(np.float64)\n",
    "y_train = df_prep[:891].Survived.values\n",
    "# Applying PCA\n",
    "# We declare n_components = None to find n_componenets by view explained_variance_ratio_\n",
    "# then set the nbr \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=15)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression |██████████████████████████████████████████████████| 100.00 % (7 / 7) (00:00:01)\n",
      "The best classifier is Random Forest\n",
      "The accuracy : 79.24 %\n",
      "The duration of execution : 00 hours 00 minutes 01 seconds\n",
      "Number of tests = 7 / 7 tests\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "# generate the classifiers with PCA algorithm\n",
    "# key : name of algorithm\n",
    "# value : list of size 2 which contains algorithm and params of algo\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": [LogisticRegression, {'random_state': 0}],\n",
    "    \"KNN\": [KNeighborsClassifier,\n",
    "            {'n_neighbors': 1, 'metric': 'minkowski', 'p': 2}],\n",
    "    \"SVM rbf\": [SVC, {'kernel': 'rbf', 'random_state': 0}],\n",
    "#     \"SVM poly\": [SVC, {'kernel': 'poly', 'random_state': 0}],\n",
    "    \"SVM sigmoid\": [SVC, {'kernel': 'sigmoid', 'random_state': 0}],\n",
    "#     \"SVM precomputed\": [SVC, {'kernel': 'precomputed', 'random_state': 0}],\n",
    "#     \"SVM linear\": [SVC, {'kernel': 'linear', 'random_state': 0}],\n",
    "    \"Naive Bayes\": [GaussianNB, {}],\n",
    "    \"Decision Tree\": [DecisionTreeClassifier, {'criterion': \"entropy\",\n",
    "                                               'random_state': 0}],\n",
    "    \"Random Forest\": [RandomForestClassifier,\n",
    "                      {'n_estimators': 10,\n",
    "                       'criterion': 'entropy',\n",
    "                       'random_state': 0}]\n",
    "}\n",
    "# generate threads for multiple ML algorithms\n",
    "len_algorithms = classifiers.__len__()\n",
    "# count of all columns in data\n",
    "len_cols = len(df_prep.columns)\n",
    "# use K fold\n",
    "kf = KFold(n_splits=9)\n",
    "\n",
    "results = []\n",
    "best_classifier = {'accuracy': -1}\n",
    "\n",
    "# generate classifiers\n",
    "for name_classifier, [classifier, params] in classifiers.items():\n",
    "    ml_classifier = classifier(**params)\n",
    "    scores = cross_val_score(ml_classifier, X_train, y_train, cv=kf)\n",
    "    # save the result\n",
    "    # print(name_classifier)\n",
    "    results.append({\n",
    "        \"classifier\": ml_classifier,\n",
    "        \"algorithm\": name_classifier,\n",
    "        \"accuracy\": np.mean(scores)\n",
    "    })\n",
    "\n",
    "    # print the progression\n",
    "    progress_value = results.__len__() * 100. / len_algorithms\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(\"Progression |%-50s| %.2f %% (%d / %d) (%s)\" %\n",
    "                     (\"\\u2588\" * int(progress_value / 2.),\n",
    "                      progress_value,\n",
    "                      results.__len__(), len_algorithms,\n",
    "                      strftime(\"%H:%M:%S\", gmtime(time() - start_time))\n",
    "                      )\n",
    "                     )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# sort and view results\n",
    "best_classifier = max(results, key=lambda d: d['accuracy'])\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(\"\\nThe best classifier is %s\" % best_classifier['algorithm'])\n",
    "print(\"The accuracy : %.2f %%\" % (best_classifier['accuracy'] * 100.))\n",
    "print(\"The duration of execution : %s\" %\n",
    "      strftime(\"%H hours %M minutes %S seconds\", gmtime(end_time - start_time))\n",
    "      )\n",
    "print(\"Number of tests = %d / %d tests\" % (results.__len__(), len_algorithms))\n",
    "\n",
    "# add the test data to best classifier\n",
    "best_classifier['classifier'].fit(X_train, y_train)\n",
    "best_classifier['pca'] = pca\n",
    "# save label encoders\n",
    "best_classifier['label_encoders'] = label_encoders\n",
    "\n",
    "# Save best classifier to pickle as dictionary\n",
    "with open('classifiers/best_classifier_pca.pik', 'wb') as wp:\n",
    "    pickle.dump(best_classifier, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "-------------------\n",
      "Columns : ['Pclass', 'Sex', 'SibSp', 'NameType', 'FamilySize', 'TicketNumDigitStart', 'CabinCount', 'PclassPower', 'PersonPerCabin']\n",
      "Len of features : 9 columns\n",
      "\n",
      "Decision Tree\n",
      "-------------\n",
      "Columns : ['NameType', 'TicketNum', 'FarePerPerson']\n",
      "Len of features : 3 columns\n",
      "\n",
      "Random Forest\n",
      "-------------\n",
      "Columns : ['Sex', 'Age', 'Fare', 'NameType', 'FamilySize', 'TicketNum', 'TicketNumDigitStart', 'FarePerPerson', 'CabinCode', 'NbrOfCabin', 'MaleCount', 'FemaleCount', 'PclassPower', 'PclassPowerFare', 'FarePerCabin']\n",
      "Len of features : 15 columns\n",
      "\n",
      "Count of supports : {'Logistic Regression': 9, 'Decision Tree': 3, 'Random Forest': 15}\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "    \n",
    "df_prep = dataframe\n",
    "# get the list of target Survived\n",
    "y = df_prep[:891].Survived.values\n",
    "df_prep = df_prep.drop(['Survived'], axis=1)\n",
    "\n",
    "# get the cols of type \"object\"\n",
    "object_cols = df_prep.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = {}\n",
    "for obj_col in object_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df_prep[obj_col])\n",
    "    df_prep[[obj_col]] = df_prep[[obj_col]].apply(label_encoder.transform)\n",
    "    label_encoders[obj_col] = label_encoder\n",
    "    \n",
    "classifiers = {\n",
    "    \"Logistic Regression\": [LogisticRegression, {'random_state': 0}],\n",
    "#     \"KNN\": [KNeighborsClassifier,\n",
    "#             {'n_neighbors': 1, 'metric': 'minkowski', 'p': 2}],\n",
    "#     \"SVM rbf\": [SVC, {'kernel': 'rbf', 'C': 1, 'random_state': 0}],\n",
    "    # \"SVM poly\": [SVC, {'kernel': 'poly', 'random_state': 0}],\n",
    "    # \"SVM sigmoid\": [SVC, {'kernel': 'sigmoid', 'random_state': 0}],\n",
    "    # \"SVM precomputed\": [SVC, {'kernel': 'precomputed', 'random_state': 0}],\n",
    "#     \"SVM linear\": [SVC, {'kernel': 'linear', 'C': 1, 'random_state': 0}],\n",
    "#     \"Naive Bayes\": [GaussianNB, {}],\n",
    "    \"Decision Tree\": [DecisionTreeClassifier, {'criterion': \"entropy\",\n",
    "                                               'random_state': 0}],\n",
    "    \"Random Forest\": [RandomForestClassifier,\n",
    "                      {'n_estimators': 10,\n",
    "                       'criterion': 'entropy',\n",
    "                       'random_state': 0}]\n",
    "}\n",
    "\n",
    "len_algorithms = classifiers.__len__()\n",
    "# use K fold\n",
    "kf = KFold(n_splits=9)\n",
    "\n",
    "x = df_prep[:891].values.astype(np.float64)\n",
    "\n",
    "count_support = {}\n",
    "\n",
    "for name_classifier, [classifier, params] in classifiers.items():\n",
    "    selector = RFECV(estimator=classifier(**params), step=1, cv=kf, scoring='accuracy')\n",
    "    selector = selector.fit(x, y)\n",
    "    columns = list(df_prep.columns[selector.support_])\n",
    "    count_support[name_classifier] = len(columns)\n",
    "    print(name_classifier)\n",
    "    print('-' * len(name_classifier))\n",
    "    print(\"Columns :\", columns)\n",
    "    print(\"Len of features : %d columns\" % len(columns))\n",
    "    print()\n",
    "    \n",
    "print(\"Count of supports :\", count_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "df_prep = dataframe[:891]\n",
    "# get the list of target Survived\n",
    "y = df_prep.Survived.values\n",
    "df_prep = df_prep.drop(['Survived'], axis=1)\n",
    "\n",
    "# get the cols of type \"object\"\n",
    "object_cols = df_prep.select_dtypes(\"object\").columns\n",
    "# Convert the categorical data to numbers\n",
    "label_encoders = {}\n",
    "for obj_col in object_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df_prep[obj_col])\n",
    "    df_prep[[obj_col]] = df_prep[[obj_col]].apply(label_encoder.transform)\n",
    "    label_encoders[obj_col] = label_encoder\n",
    "# df_prep[object_cols] = df_prep[object_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# generate the classifiers without PCA Algorithm\n",
    "# key : name of algorithm\n",
    "# value : list of size 2 which contains algorithm and params of algo\n",
    "classifiers = {\n",
    "#     \"Logistic Regression\": [LogisticRegression, {'random_state': 0}],\n",
    "#     \"KNN\": [KNeighborsClassifier,\n",
    "#             {'n_neighbors': 1, 'metric': 'minkowski', 'p': 2}],\n",
    "#     \"SVM rbf\": [SVC, {'kernel': 'rbf', 'random_state': 0}],\n",
    "    # \"SVM poly\": [SVC, {'kernel': 'poly', 'random_state': 0}],\n",
    "    # \"SVM sigmoid\": [SVC, {'kernel': 'sigmoid', 'random_state': 0}],\n",
    "    # \"SVM precomputed\": [SVC, {'kernel': 'precomputed', 'random_state': 0}],\n",
    "    # \"SVM linear\": [SVC, {'kernel': 'linear', 'random_state': 0}],\n",
    "#     \"Naive Bayes\": [GaussianNB, {}],\n",
    "#     \"Decision Tree\": [DecisionTreeClassifier, {'criterion': \"entropy\",\n",
    "#                                                'random_state': 0}]\n",
    "    \"Random Forest\": [RandomForestClassifier,\n",
    "                      {'n_estimators': 10,\n",
    "                       'criterion': 'entropy',\n",
    "                       'random_state': 0}]\n",
    "}\n",
    "# generate threads for multiple ML algorithms\n",
    "len_algorithms = classifiers.__len__()\n",
    "# count of all columns in data\n",
    "len_cols = len(df_prep.columns)\n",
    "# max_nbr_f = df_prep.columns.__len__()\n",
    "# max_nbr_f = 3\n",
    "# min_nbr_f = max_nbr_f // 5 + 1\n",
    "# start_nbr_f = start_nbr_f if start_nbr_f != 0 else 1\n",
    "nbr_tests = sum(\n",
    "    len(list(itertools.combinations(range(len_cols), nbr_features))) for\n",
    "    nbr_features in [nbrf for namec, nbrf in count_support.items() if namec in classifiers.keys()]\n",
    ")\n",
    "# use K fold\n",
    "kf = KFold(n_splits=9)\n",
    "\n",
    "results = []\n",
    "best_classifier = {'accuracy': -1}\n",
    "\n",
    "# generate classifiers\n",
    "for name_classifier, [classifier, params] in classifiers.items():\n",
    "    for indexes_cols in itertools.combinations(range(len_cols), count_support[name_classifier]):\n",
    "        columns = [col for index, col in enumerate(df_prep.columns) if index in indexes_cols]\n",
    "        x = df_prep[columns].values.astype(np.float64)\n",
    "        \n",
    "        ml_classifier = classifier(**params)\n",
    "        scores = cross_val_score(ml_classifier, x, y, cv=kf)\n",
    "        # save the result\n",
    "        # print(name_classifier)\n",
    "        results.append({\n",
    "            \"x_y\": [x, y],\n",
    "#                 \"dummy_var\": onehotencoder,\n",
    "#                 \"feature_scaling\": sc,\n",
    "            \"classifier\": ml_classifier,\n",
    "            \"features\": list(columns),\n",
    "            \"algorithm\": name_classifier,\n",
    "            \"accuracy\": max(scores)\n",
    "        })\n",
    "\n",
    "        # print the progression\n",
    "        progress_value = results.__len__() * 100. / nbr_tests\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(\"Progression |%-50s| %.2f %% (%d / %d) (%s)\" %\n",
    "                         (\"\\u2588\" * int(progress_value / 2.),\n",
    "                          progress_value,\n",
    "                          results.__len__(), nbr_tests,\n",
    "                          strftime(\"%H:%M:%S\", gmtime(time() - start_time))\n",
    "                          )\n",
    "                         )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "# sort and view results\n",
    "max_accuracy = max([d['accuracy'] for d in results])\n",
    "best_classifier = min(\n",
    "    filter(lambda d: d['accuracy'] == max_accuracy, results),\n",
    "    key=lambda d: len(d['features'])\n",
    ")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(\"\\nThe best classifier is %s\" % best_classifier['algorithm'])\n",
    "print(\"The accuracy : %.2f %%\" % (best_classifier['accuracy'] * 100.))\n",
    "print(\"The columns : %s\" % best_classifier['features'])\n",
    "print(\"The duration of execution : %s\" %\n",
    "      strftime(\"%H hours %M minutes %S seconds\", gmtime(end_time - start_time))\n",
    "      )\n",
    "print(\"Number of tests = %d / %d tests\" % (results.__len__(), nbr_tests))\n",
    "\n",
    "# add the test data to best classifier\n",
    "x, y = best_classifier['x_y']\n",
    "best_classifier['classifier'].fit(x, y)\n",
    "\n",
    "# save label encoders\n",
    "best_classifier['label_encoders'] = label_encoders\n",
    "\n",
    "# Save best classifier to pickle as dictionary\n",
    "with open('best_classifier.pik', 'wb') as wp:\n",
    "    pickle.dump(best_classifier, wp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
